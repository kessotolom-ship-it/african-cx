/**
 * ============================================================
 *  Processeur MultimÃ©dia â€” Voix (Whisper) + Vision (GPT-4o)
 * ============================================================
 *
 *  Ce module gÃ¨re la transcription audio et l'analyse d'images
 *  pour le chatbot WhatsApp. Il utilise les APIs OpenAI :
 *
 *    ğŸ¤ Whisper  â†’ Transcription audio (notes vocales)
 *    ğŸ–¼ï¸ GPT-4o   â†’ Analyse d'images (reÃ§us, documents, CNI)
 *
 *  Variable d'environnement requise :
 *    - OPENAI_API_KEY
 * ============================================================
 */

import OpenAI from 'openai';

// â”€â”€â”€ Client OpenAI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function getOpenAI(): OpenAI {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
        throw new Error('OPENAI_API_KEY is not set');
    }
    return new OpenAI({ apiKey });
}

// â”€â”€â”€ Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export interface TranscriptionResult {
    text: string;
    language?: string;
    duration?: number;
}

export interface VisionResult {
    description: string;
    /** Type dÃ©tectÃ© : receipt, id_card, screenshot, document, photo, unknown */
    detectedType: string;
}

export interface MediaDownloadResult {
    buffer: Buffer;
    mimeType: string;
    fileName: string;
}

// â”€â”€â”€ TÃ©lÃ©chargement de mÃ©dias â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * TÃ©lÃ©charge un fichier mÃ©dia depuis une URL (Evolution API ou WhatsApp CDN)
 * Evolution API expose les mÃ©dias via son endpoint de tÃ©lÃ©chargement
 */
export async function downloadMediaFromEvolution(
    messageId: string,
    instanceName: string
): Promise<MediaDownloadResult | null> {
    const baseUrl = process.env.EVOLUTION_API_URL?.replace(/\/$/, '');
    const apiKey = process.env.EVOLUTION_API_KEY;

    if (!baseUrl || !apiKey) {
        console.error('[MEDIA] Missing Evolution API config for media download');
        return null;
    }

    try {
        // Evolution API v2 : GET /chat/getBase64FromMediaMessage/{instance}
        const response = await fetch(
            `${baseUrl}/chat/getBase64FromMediaMessage/${instanceName}`,
            {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'apikey': apiKey,
                },
                body: JSON.stringify({
                    message: { key: { id: messageId } },
                    convertToMp4: false,
                }),
            }
        );

        if (!response.ok) {
            const errorText = await response.text();
            console.error(`[MEDIA] Download failed: ${response.status} â€” ${errorText}`);
            return null;
        }

        const data = await response.json();

        if (!data.base64) {
            console.error('[MEDIA] No base64 data in response');
            return null;
        }

        const buffer = Buffer.from(data.base64, 'base64');
        return {
            buffer,
            mimeType: data.mimetype || 'application/octet-stream',
            fileName: data.fileName || `media_${messageId}`,
        };
    } catch (error) {
        console.error('[MEDIA] Download error:', error);
        return null;
    }
}

/**
 * TÃ©lÃ©charge un mÃ©dia directement depuis une URL publique
 */
export async function downloadMediaFromUrl(url: string): Promise<MediaDownloadResult | null> {
    try {
        const response = await fetch(url);
        if (!response.ok) {
            console.error(`[MEDIA] URL download failed: ${response.status}`);
            return null;
        }

        const arrayBuffer = await response.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        const mimeType = response.headers.get('content-type') || 'application/octet-stream';

        return {
            buffer,
            mimeType,
            fileName: `media_${Date.now()}`,
        };
    } catch (error) {
        console.error('[MEDIA] URL download error:', error);
        return null;
    }
}

// â”€â”€â”€ ğŸ¤ WHISPER â€” Transcription Audio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * Transcrit un message audio en texte via OpenAI Whisper
 * 
 * Langues supportÃ©es : franÃ§ais, anglais, arabe, wolof, bambara, etc.
 * Whisper dÃ©tecte automatiquement la langue.
 * 
 * @param audioBuffer - Buffer contenant l'audio (ogg, mp3, m4a, wav, webm)
 * @param mimeType - Type MIME de l'audio
 * @returns Texte transcrit + langue dÃ©tectÃ©e
 */
export async function transcribeAudio(
    audioBuffer: Buffer,
    mimeType: string = 'audio/ogg'
): Promise<TranscriptionResult> {
    const openai = getOpenAI();

    // DÃ©terminer l'extension depuis le mime type
    const extMap: Record<string, string> = {
        'audio/ogg': 'ogg',
        'audio/ogg; codecs=opus': 'ogg',
        'audio/mpeg': 'mp3',
        'audio/mp4': 'm4a',
        'audio/x-m4a': 'm4a',
        'audio/wav': 'wav',
        'audio/webm': 'webm',
        'audio/amr': 'amr',
    };

    // Normaliser le mimeType (enlever les paramÃ¨tres aprÃ¨s ;)
    const baseMime = mimeType.split(';')[0].trim();
    const ext = extMap[baseMime] || 'ogg';

    console.log(`[WHISPER] Transcription audio (${(audioBuffer.length / 1024).toFixed(1)} KB, ${baseMime})`);

    try {
        // CrÃ©er un objet compatible pour l'API OpenAI
        // Extraire un ArrayBuffer propre depuis le Buffer pour compatibilitÃ© TS stricte
        const ab = audioBuffer.buffer.slice(
            audioBuffer.byteOffset,
            audioBuffer.byteOffset + audioBuffer.byteLength
        ) as ArrayBuffer;
        const file = new File([ab], `voice.${ext}`, { type: baseMime });

        const transcription = await openai.audio.transcriptions.create({
            model: 'whisper-1',
            file: file,
            language: 'fr', // Hint franÃ§ais mais Whisper dÃ©tecte auto
            response_format: 'verbose_json',
            prompt: 'Ce message est une note vocale WhatsApp. Le locuteur parle probablement franÃ§ais ou une langue africaine.',
        });

        const result: TranscriptionResult = {
            text: transcription.text || '',
            language: (transcription as any).language || 'fr',
            duration: (transcription as any).duration || undefined,
        };

        console.log(`[WHISPER] âœ… Transcrit (${result.language}, ${result.duration?.toFixed(1)}s): "${result.text.substring(0, 80)}..."`);

        return result;
    } catch (error: any) {
        console.error('[WHISPER] Transcription error:', error.message);
        throw new Error(`Whisper transcription failed: ${error.message}`);
    }
}

// â”€â”€â”€ ğŸ–¼ï¸ GPT-4o VISION â€” Analyse d'Images â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * Analyse une image via GPT-4o Vision pour le contexte fintech
 * 
 * Cas d'usage typiques :
 *  - ğŸ“¸ Photo d'un reÃ§u de transaction
 *  - ğŸªª Photo d'une piÃ¨ce d'identitÃ© (CNI, passeport)
 *  - ğŸ“± Capture d'Ã©cran d'une erreur
 *  - ğŸ“„ Photo d'un document officiel
 * 
 * @param imageBuffer - Buffer contenant l'image
 * @param mimeType - Type MIME de l'image (image/jpeg, image/png, etc.)
 * @param caption - LÃ©gende optionnelle envoyÃ©e par l'utilisateur
 * @returns Description textuelle dÃ©taillÃ©e + type dÃ©tectÃ©
 */
export async function analyzeImage(
    imageBuffer: Buffer,
    mimeType: string = 'image/jpeg',
    caption?: string
): Promise<VisionResult> {
    const openai = getOpenAI();

    const base64Image = imageBuffer.toString('base64');
    const dataUrl = `data:${mimeType};base64,${base64Image}`;

    console.log(`[VISION] Analyse image (${(imageBuffer.length / 1024).toFixed(1)} KB, ${mimeType})`);

    try {
        const response = await openai.chat.completions.create({
            model: 'gpt-4o',
            max_tokens: 500,
            messages: [
                {
                    role: 'system',
                    content: `Tu es un assistant visuel pour Solimi Pay, un service de paiement mobile en Afrique de l'Ouest.

Ton rÃ´le est d'analyser les images envoyÃ©es par les clients WhatsApp et de fournir une description prÃ©cise et utile pour un agent de support.

Types d'images possibles :
- **receipt** : ReÃ§u de transaction (extrais : montant, date, rÃ©fÃ©rence, statut, opÃ©rateur)
- **id_card** : PiÃ¨ce d'identitÃ© (mentionne le type mais NE LIS PAS les infos personnelles pour la sÃ©curitÃ©)
- **screenshot** : Capture d'Ã©cran d'app ou d'erreur (dÃ©cris ce qu'on voit)
- **document** : Document officiel, facture, contrat
- **photo** : Autre photo

RÃ©ponds TOUJOURS en franÃ§ais. Sois concis mais prÃ©cis.
Format ta rÃ©ponse ainsi :
TYPE: [receipt|id_card|screenshot|document|photo|unknown]
DESCRIPTION: [description dÃ©taillÃ©e en 2-3 phrases]`,
                },
                {
                    role: 'user',
                    content: [
                        {
                            type: 'image_url',
                            image_url: {
                                url: dataUrl,
                                detail: 'low', // Ã‰conomise les tokens, suffisant pour la plupart des cas
                            },
                        },
                        {
                            type: 'text',
                            text: caption
                                ? `Le client a envoyÃ© cette image avec le message : "${caption}"`
                                : 'Le client a envoyÃ© cette image sans message. DÃ©cris ce que tu vois.',
                        },
                    ],
                },
            ],
        });

        const content = response.choices[0]?.message?.content || '';

        // Parser le type et la description
        const typeMatch = content.match(/TYPE:\s*(\w+)/i);
        const descMatch = content.match(/DESCRIPTION:\s*([\s\S]+)/i);

        const result: VisionResult = {
            detectedType: typeMatch?.[1]?.toLowerCase() || 'unknown',
            description: descMatch?.[1]?.trim() || content.trim(),
        };

        console.log(`[VISION] âœ… Type: ${result.detectedType} â€” "${result.description.substring(0, 80)}..."`);

        return result;
    } catch (error: any) {
        console.error('[VISION] Analysis error:', error.message);
        throw new Error(`Vision analysis failed: ${error.message}`);
    }
}

// â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * VÃ©rifie si un type MIME est un format audio supportÃ© par Whisper
 */
export function isSupportedAudioFormat(mimeType: string): boolean {
    const supported = [
        'audio/ogg', 'audio/mpeg', 'audio/mp3', 'audio/mp4',
        'audio/x-m4a', 'audio/wav', 'audio/webm', 'audio/amr',
        'audio/aac', 'audio/flac',
    ];
    const baseMime = mimeType.split(';')[0].trim();
    return supported.includes(baseMime);
}

/**
 * VÃ©rifie si un type MIME est un format image supportÃ© par GPT-4o Vision
 */
export function isSupportedImageFormat(mimeType: string): boolean {
    const supported = [
        'image/jpeg', 'image/jpg', 'image/png', 'image/gif',
        'image/webp', 'image/bmp',
    ];
    const baseMime = mimeType.split(';')[0].trim();
    return supported.includes(baseMime);
}

/**
 * VÃ©rifie si le buffer est trop gros pour Ãªtre traitÃ©
 * Whisper : max 25 MB
 * Vision  : max ~20 MB (recommandÃ© < 5 MB)
 */
export function isFileTooLarge(buffer: Buffer, type: 'audio' | 'image'): boolean {
    const maxSizes = {
        audio: 25 * 1024 * 1024,  // 25 MB
        image: 20 * 1024 * 1024,  // 20 MB
    };
    return buffer.length > maxSizes[type];
}
